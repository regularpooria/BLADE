{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.bugsinpy_utils import *\n",
    "from run_ast_old import extract_chunks, get_python_files, hash_file\n",
    "import numpy\n",
    "import os, json\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique files and common files for more efficient chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was fb9e72309a Merge pull request #17462 from anntzer/gtk_render_figure\n",
      "HEAD is now at cdf9e30e4f Merge pull request #14610 from meeseeksmachine/auto-backport-of-pr-14579-on-v3.1.x\n",
      "Processing files: 100%|██████████| 768/768 [00:01<00:00, 394.24file/s]\n",
      "Previous HEAD position was cdf9e30e4f Merge pull request #14610 from meeseeksmachine/auto-backport-of-pr-14579-on-v3.1.x\n",
      "HEAD is now at dbc35a9d62 Merge pull request #16683 from anntzer/gluespec\n",
      "Processing files: 100%|██████████| 761/761 [00:01<00:00, 405.05file/s]\n",
      "Previous HEAD position was dbc35a9d62 Merge pull request #16683 from anntzer/gluespec\n",
      "HEAD is now at e92685a264 Merge pull request #15254 from anntzer/propagate-decorators\n",
      "Processing files: 100%|██████████| 754/754 [00:01<00:00, 439.99file/s]\n",
      "Previous HEAD position was e92685a264 Merge pull request #15254 from anntzer/propagate-decorators\n",
      "HEAD is now at fb9e72309a Merge pull request #17462 from anntzer/gtk_render_figure\n",
      "Processing files: 100%|██████████| 759/759 [00:01<00:00, 416.12file/s]\n",
      "Previous HEAD position was fb9e72309a Merge pull request #17462 from anntzer/gtk_render_figure\n",
      "HEAD is now at 8673167d4c Merge pull request #17415 from Sonic-Amiga/p.fedin/5962\n",
      "Processing files: 100%|██████████| 759/759 [00:01<00:00, 385.86file/s]\n",
      "Previous HEAD position was 8673167d4c Merge pull request #17415 from Sonic-Amiga/p.fedin/5962\n",
      "HEAD is now at a87cd8a4c4 Merge pull request #15389 from meeseeksmachine/auto-backport-of-pr-15379-on-v3.2.x\n",
      "Processing files: 100%|██████████| 764/764 [00:01<00:00, 392.23file/s]\n",
      "Previous HEAD position was a87cd8a4c4 Merge pull request #15389 from meeseeksmachine/auto-backport-of-pr-15379-on-v3.2.x\n",
      "HEAD is now at 5e046f72ae Merge pull request #17572 from sadielbartholomew/setp-and-getp-example-clarity\n",
      "Processing files: 100%|██████████| 760/760 [00:01<00:00, 416.82file/s]\n",
      "Previous HEAD position was 5e046f72ae Merge pull request #17572 from sadielbartholomew/setp-and-getp-example-clarity\n",
      "HEAD is now at b31d64ce39 Merge pull request #16900 from timhoffm/doc-common-texification\n",
      "Processing files: 100%|██████████| 755/755 [00:01<00:00, 406.25file/s]\n",
      "Previous HEAD position was b31d64ce39 Merge pull request #16900 from timhoffm/doc-common-texification\n",
      "HEAD is now at 793c6b0538 Merge pull request #17532 from MaozGelbart/title_docfix\n",
      "Processing files: 100%|██████████| 760/760 [00:01<00:00, 395.41file/s]\n",
      "Previous HEAD position was 793c6b0538 Merge pull request #17532 from MaozGelbart/title_docfix\n",
      "HEAD is now at 805f451b71 Merge pull request #16168 from meeseeksmachine/auto-backport-of-pr-16166-on-v3.2.x\n",
      "Processing files: 100%|██████████| 765/765 [00:02<00:00, 356.89file/s]\n",
      "Previous HEAD position was 805f451b71 Merge pull request #16168 from meeseeksmachine/auto-backport-of-pr-16166-on-v3.2.x\n",
      "HEAD is now at 969513e2a5 Merge pull request #17469 from anntzer/qv\n",
      "Processing files: 100%|██████████| 759/759 [00:01<00:00, 397.54file/s]\n",
      "Previous HEAD position was 969513e2a5 Merge pull request #17469 from anntzer/qv\n",
      "HEAD is now at e240493a89 Merge pull request #15848 from anntzer/envvar\n",
      "Processing files: 100%|██████████| 765/765 [00:02<00:00, 362.75file/s]\n",
      "Previous HEAD position was e240493a89 Merge pull request #15848 from anntzer/envvar\n",
      "HEAD is now at c404d1f716 Merge pull request #17587 from QuLogic/fix-docs\n",
      "Processing files: 100%|██████████| 762/762 [00:02<00:00, 305.55file/s]\n",
      "Previous HEAD position was c404d1f716 Merge pull request #17587 from QuLogic/fix-docs\n",
      "HEAD is now at 2c845db9d9 Merge pull request #16779 from pibion/improve-doc-contrib\n",
      "Processing files: 100%|██████████| 754/754 [00:06<00:00, 124.02file/s]\n",
      "Previous HEAD position was 2c845db9d9 Merge pull request #16779 from pibion/improve-doc-contrib\n",
      "HEAD is now at 89ff308306 Merge pull request #16360 from meeseeksmachine/auto-backport-of-pr-16347-on-v3.2.x\n",
      "Processing files: 100%|██████████| 765/765 [00:01<00:00, 383.38file/s]\n",
      "Previous HEAD position was 89ff308306 Merge pull request #16360 from meeseeksmachine/auto-backport-of-pr-16347-on-v3.2.x\n",
      "HEAD is now at 2a3707d9c3 Markers with fillstyle 'none' should return False for is_filled()\n",
      "Processing files: 100%|██████████| 760/760 [00:02<00:00, 369.22file/s]\n",
      "Previous HEAD position was 2a3707d9c3 Markers with fillstyle 'none' should return False for is_filled()\n",
      "HEAD is now at 54bd6f19b2 Merge pull request #17400 from anntzer/wxex\n",
      "Processing files: 100%|██████████| 759/759 [00:02<00:00, 296.31file/s]\n",
      "Previous HEAD position was 54bd6f19b2 Merge pull request #17400 from anntzer/wxex\n",
      "HEAD is now at 7d958c63f4 Merge pull request #16260 from meeseeksmachine/auto-backport-of-pr-16259-on-v3.2.x\n",
      "Processing files: 100%|██████████| 765/765 [00:02<00:00, 318.18file/s]\n",
      "Previous HEAD position was 7d958c63f4 Merge pull request #16260 from meeseeksmachine/auto-backport-of-pr-16259-on-v3.2.x\n",
      "HEAD is now at 47cfa35fc0 Clean up and clarify Normalize docs (#16271)\n",
      "Processing files: 100%|██████████| 763/763 [00:02<00:00, 330.85file/s]\n",
      "Previous HEAD position was 47cfa35fc0 Clean up and clarify Normalize docs (#16271)\n",
      "HEAD is now at bb6a4af984 Merge pull request #14702 from anntzer/qtnavbarhighdpi\n",
      "Processing files: 100%|██████████| 764/764 [00:02<00:00, 347.91file/s]\n",
      "Previous HEAD position was bb6a4af984 Merge pull request #14702 from anntzer/qtnavbarhighdpi\n",
      "HEAD is now at 9a5473dbac Merge pull request #14777 from meeseeksmachine/auto-backport-of-pr-14775-on-v3.1.x\n",
      "Processing files: 100%|██████████| 768/768 [00:02<00:00, 303.21file/s]\n",
      "HEAD is now at 9a5473dbac Merge pull request #14777 from meeseeksmachine/auto-backport-of-pr-14775-on-v3.1.x\n",
      "Processing files: 100%|██████████| 768/768 [00:02<00:00, 306.04file/s]\n",
      "Previous HEAD position was 9a5473dbac Merge pull request #14777 from meeseeksmachine/auto-backport-of-pr-14775-on-v3.1.x\n",
      "HEAD is now at 6a8e39f4eb Merge pull request #16520 from anntzer/np115\n",
      "Processing files: 100%|██████████| 762/762 [00:02<00:00, 337.90file/s]\n",
      "Previous HEAD position was 6a8e39f4eb Merge pull request #16520 from anntzer/np115\n",
      "HEAD is now at 58c66982d9 Merge pull request #16265 from anntzer/lowerspy\n",
      "Processing files: 100%|██████████| 762/762 [00:02<00:00, 360.74file/s]\n",
      "Previous HEAD position was 58c66982d9 Merge pull request #16265 from anntzer/lowerspy\n",
      "HEAD is now at 3b26ee6f6b Merge pull request #14238 from meeseeksmachine/auto-backport-of-pr-14164-on-v3.1.x\n",
      "Processing files: 100%|██████████| 767/767 [00:05<00:00, 138.86file/s]\n",
      "Previous HEAD position was 3b26ee6f6b Merge pull request #14238 from meeseeksmachine/auto-backport-of-pr-14164-on-v3.1.x\n",
      "HEAD is now at 49593b7385 Merge pull request #16908 from greglucas/quadmesh_set_array\n",
      "Processing files: 100%|██████████| 759/759 [00:01<00:00, 385.00file/s]\n",
      "Previous HEAD position was 49593b7385 Merge pull request #16908 from greglucas/quadmesh_set_array\n",
      "HEAD is now at f8459a513c Use cbook._setattr_cm more.\n",
      "Processing files: 100%|██████████| 755/755 [00:01<00:00, 395.06file/s]\n",
      "Previous HEAD position was c81d90f076 ERR: Raise a better error for numpy singletons in Index (#33026)\n",
      "HEAD is now at 7705cd24a6 DOC/BLD: remove old sphinx pin (#28804)\n",
      "Processing files: 100%|██████████| 279/279 [00:01<00:00, 164.99file/s]\n",
      "Previous HEAD position was 7705cd24a6 DOC/BLD: remove old sphinx pin (#28804)\n",
      "HEAD is now at 6f395ad421 Replaced set comprehension with a generator (#31229)\n",
      "Processing files: 100%|██████████| 289/289 [00:01<00:00, 186.02file/s]\n",
      "Previous HEAD position was 6f395ad421 Replaced set comprehension with a generator (#31229)\n",
      "HEAD is now at 46a77f689e TST: parametrize some indexing tests (#31767)\n",
      "Processing files: 100%|██████████| 289/289 [00:01<00:00, 179.90file/s]\n",
      "Previous HEAD position was 46a77f689e TST: parametrize some indexing tests (#31767)\n",
      "HEAD is now at 6e3537dbab CLN: Static types in `pandas/_lib/lib.pyx` (#33329)\n",
      "Processing files:  42%|████▏     | 123/294 [00:01<00:01, 116.09file/s]"
     ]
    }
   ],
   "source": [
    "projects = get_projects()\n",
    "projects.remove(\"ansible\")\n",
    "for project in projects:\n",
    "    clone_project(project)\n",
    "    bugs = get_bugs(project)\n",
    "    for bug in bugs:\n",
    "        info = get_bug_info(project, bug)\n",
    "        bug_id = f\"{project}:{bug}\"\n",
    "        checkout_to_commit(project, info[\"buggy_commit_id\"])\n",
    "        python_files = get_python_files(f\"tmp/{project}\")\n",
    "                \n",
    "        os.makedirs(f\"dataset/{project}/{bug}\", exist_ok=True)\n",
    "        chunks = extract_chunks(python_files)\n",
    "        with open(\n",
    "            f\"dataset/{project}/{bug}/code_chunks.json\", \"w\", encoding=\"utf-8\"\n",
    "        ) as f:\n",
    "            json.dump(chunks, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the hashes for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from scripts.embedding import BATCH_SIZE, embed\n",
    "\n",
    "projects = get_projects()\n",
    "embedding_cache = {}\n",
    "texts_to_embed = []\n",
    "text_to_indices = {}\n",
    "\n",
    "# First pass: collect all unique texts and track their usage\n",
    "for project in projects:\n",
    "    bugs = get_bugs(project)\n",
    "    for bug in bugs:\n",
    "        with open(\n",
    "            f\"dataset/{project}/{bug}/code_chunks.json\", \"r\", encoding=\"utf-8\"\n",
    "        ) as f:\n",
    "            chunks = json.load(f)\n",
    "            texts = [chunk[\"code\"] for chunk in chunks]\n",
    "            indices = []\n",
    "\n",
    "            for text in texts:\n",
    "                if text not in embedding_cache:\n",
    "                    if text not in text_to_indices:\n",
    "                        text_to_indices[text] = []\n",
    "                        texts_to_embed.append(text)\n",
    "                    text_to_indices[text].append((project, bug))\n",
    "                else:\n",
    "                    # Already cached\n",
    "                    pass\n",
    "\n",
    "# Second pass: Embed all unique texts in batch\n",
    "print(f\"Embedding {len(texts_to_embed)} unique chunks...\")\n",
    "all_embeddings = embed(texts_to_embed, batch_size=BATCH_SIZE, show_progress_bar=True)\n",
    "\n",
    "# Populate cache\n",
    "for i, text in enumerate(texts_to_embed):\n",
    "    embedding_cache[text] = all_embeddings[i]\n",
    "\n",
    "# Final pass: write per-bug embedding files\n",
    "for project in projects:\n",
    "    bugs = get_bugs(project)\n",
    "    for bug in bugs:\n",
    "        with open(\n",
    "            f\"dataset/{project}/{bug}/code_chunks.json\", \"r\", encoding=\"utf-8\"\n",
    "        ) as f:\n",
    "            chunks = json.load(f)\n",
    "            texts = [chunk[\"code\"] for chunk in chunks]\n",
    "            embeddings = np.array([embedding_cache[text] for text in texts])\n",
    "            os.makedirs(f\"dataset/{project}/{bug}\", exist_ok=True)\n",
    "            np.save(f\"dataset/{project}/{bug}/embedding.npy\", embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
