{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all of the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.embedding import model, MODEL_NAME, BATCH_SIZE, embed, index_embeddings\n",
    "from scripts.bugsinpy_utils import *\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure the directories exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.abspath(f\"tmp/ast/results\"), exist_ok=True)\n",
    "K = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running each eligible bug through the model and embedding them, after then running cosine similarity to determine which files they think it should be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_precision(y_true):\n",
    "    hits = 0\n",
    "    sum_precisions = 0.0\n",
    "    for i, rel in enumerate(y_true):\n",
    "        if rel:\n",
    "            hits += 1\n",
    "            sum_precisions += hits / (i + 1)\n",
    "    return sum_precisions / max(hits, 1)\n",
    "\n",
    "def compute_reciprocal_rank(y_true):\n",
    "    for i, rel in enumerate(y_true, start=1):  # ranks start at 1\n",
    "        if rel:\n",
    "            return 1.0 / i\n",
    "    return 0.0  # no relevant item found in top K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Batch encode\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_texts:\n\u001b[0;32m---> 26\u001b[0m     error_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membed\u001b[49m(error_texts, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m     output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bug, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(filtered_bugs, error_embeddings):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embed' is not defined"
     ]
    }
   ],
   "source": [
    "projects = get_projects()\n",
    "all_ap = []\n",
    "all_rr = []\n",
    "\n",
    "for project in projects:\n",
    "    bugs = get_bugs(project)\n",
    "    # embedding_index_path = f\"tmp/ast/embeddings/index_{project}.faiss\"\n",
    "    bug_result_path = os.path.abspath(f\"tmp/ast/results/bug_results_{project}.json\")\n",
    "    filtered_bugs = []\n",
    "    error_texts = []\n",
    "\n",
    "    # First pass: filter bugs and collect error traces\n",
    "    for bug in bugs:\n",
    "            \n",
    "        changed_files = parse_changed_files(project, bug)\n",
    "        if len(changed_files) > 1:\n",
    "            continue\n",
    "        info = get_bug_info(project, bug)\n",
    "        error = extract_python_tracebacks(project, bug)\n",
    "        if error:\n",
    "            filtered_bugs.append(bug)\n",
    "            error_texts.append(error)\n",
    "\n",
    "    # Batch encode\n",
    "    if error_texts:\n",
    "        error_embeddings = embed(error_texts, batch_size=BATCH_SIZE, show_progress_bar=True)\n",
    "\n",
    "        output = []\n",
    "\n",
    "        for bug, emb in zip(filtered_bugs, error_embeddings):\n",
    "            code_chunks_path = f\"dataset/{project}/{bug}/code_chunks.json\"\n",
    "            with open(code_chunks_path, \"r\") as f:\n",
    "                code_chunks = json.loads(f.read())\n",
    "            embedding_path = f\"dataset/{project}/{bug}/embedding.npy\"\n",
    "            embeddings = np.load(embedding_path)\n",
    "            index = index_embeddings(embeddings)\n",
    "            D, I = index.search(np.array([emb]).astype(\"float32\"), k=K)\n",
    "            search_results = {\"index\": bug, \"files\": []}\n",
    "            for idx in I[0]:\n",
    "                result = code_chunks[idx]\n",
    "                search_results[\"files\"].append(\n",
    "                    {\"file\": result[\"file\"], \"function\": result[\"name\"]}\n",
    "                )\n",
    "            output.append(search_results)\n",
    "            \n",
    "            changed_file = parse_changed_files(project, bug)[0].split(\"/\")[-1]\n",
    "            y_true = [1 if code_chunks[idx][\"file\"].split(\"/\")[-1] == changed_file else 0 for idx in I[0]]\n",
    "            ap = compute_average_precision(y_true)\n",
    "            rr = compute_reciprocal_rank(y_true)\n",
    "\n",
    "            all_ap.append(ap)\n",
    "            all_rr.append(rr)\n",
    "\n",
    "        with open(bug_result_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(output, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using that predictions to calculate success rate and show where each search was successful or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_folder = os.path.abspath(\"tmp/ast/results\")\n",
    "results_files = os.listdir(results_folder)\n",
    "def analyze(k):\n",
    "    results = {\n",
    "        \"K\": k,\n",
    "        \"model_name\": \"blaze\",\n",
    "        \"searches_failed\": [],  # [{project_name, bug_id, detected_files: list, actual_file}]\n",
    "        \"searches_passed\": [],  # [{project_name, bug_id, detected_files: list, actual_files}]\n",
    "        \"success_rate\": 0,  # out of 100 (including bugs skipped)\n",
    "        # \"MAP\": np.mean(all_ap),\n",
    "        # \"MRR\": np.mean(all_rr),\n",
    "        \"success_projects\": {},  # {project_name, success_rate, success_rate_no_skip}\n",
    "    }\n",
    "    success_projects_tmp = {}\n",
    "    count = 0\n",
    "    maximum_bugs = 0\n",
    "    for project in results_files:\n",
    "        if \".json\" not in project:\n",
    "            continue\n",
    "        project_name = project.replace(\"bug_results_\", \"\").replace(\".json\", \"\")\n",
    "        bugs = get_bugs(project_name)\n",
    "        maximum_bugs += len(bugs)\n",
    "        success_projects_tmp[project_name] = {\n",
    "            \"failed\": 0,\n",
    "            \"passed\": 0,\n",
    "            \"total\": 0,\n",
    "        }\n",
    "\n",
    "        with open(f\"{results_folder}/{project}\", \"r\", encoding=\"utf-8\") as result_file:\n",
    "            data = json.loads(result_file.read())\n",
    "            for search_result in data:\n",
    "                changed_functions = parse_changed_function_names_2(project_name, search_result[\"index\"])\n",
    "                functions_predicted = [\n",
    "                    obj[\"function\"].split(\"/\")[-1] for obj in search_result[\"files\"][:k]\n",
    "                ]\n",
    "                \n",
    "                flag = True\n",
    "                for changed_function in changed_functions:\n",
    "                    if changed_function not in functions_predicted:\n",
    "                        flag = False\n",
    "                        break\n",
    "                        \n",
    "                if flag:\n",
    "                    results[\"searches_passed\"].append(\n",
    "                        {\n",
    "                            \"project_name\": project_name,\n",
    "                            \"bug_id\": search_result[\"index\"],\n",
    "                            \"detected_functions\": functions_predicted,\n",
    "                            \"actual_functions\": changed_functions,\n",
    "                        }\n",
    "                    )\n",
    "                    success_projects_tmp[project_name][\"passed\"] += 1\n",
    "                    success_projects_tmp[project_name][\"total\"] += 1\n",
    "                else:\n",
    "                    results[\"searches_failed\"].append(\n",
    "                        {\n",
    "                            \"project_name\": project_name,\n",
    "                            \"bug_id\": search_result[\"index\"],\n",
    "                            \"detected_functions\": functions_predicted,\n",
    "                            \"actual_functions\": changed_functions,\n",
    "                        }\n",
    "                    )\n",
    "                    success_projects_tmp[project_name][\"failed\"] += 1\n",
    "                    success_projects_tmp[project_name][\"total\"] += 1\n",
    "                    \n",
    "\n",
    "\n",
    "        searches_counted = (\n",
    "            success_projects_tmp[project_name][\"passed\"]\n",
    "            + success_projects_tmp[project_name][\"failed\"]\n",
    "        )\n",
    "\n",
    "        results[\"success_projects\"][project_name] = {\n",
    "            \"success_rate\": success_projects_tmp[project_name][\"passed\"] / searches_counted,\n",
    "        } | success_projects_tmp[project_name]\n",
    "\n",
    "    results[\"success_rate\"] = len(results[\"searches_passed\"]) / (len(results[\"searches_failed\"]) + len(results[\"searches_passed\"]))\n",
    "    with open(os.path.abspath(f\"results_{k}.json\"), \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(json.dumps(results, indent=2))\n",
    "        \n",
    "analyze(1)\n",
    "analyze(5)\n",
    "analyze(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project         Passed Failed  Total  Success Rate\n",
      "==================================================\n",
      "0.16129032258064516\n",
      "0.23529411764705882\n",
      "0.2608695652173913\n",
      "0.05263157894736842\n",
      "0.1\n",
      "0.2702702702702703\n",
      "0.16129032258064516\n",
      "0.23333333333333334\n",
      "0.0\n",
      "\n",
      "Overall Success Rate: 17.49%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load your data\n",
    "with open(\"results_10.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Desired project order\n",
    "ordered_projects = [\n",
    "    \"youtube-dl\",\n",
    "    \"keras\",\n",
    "    \"matplotlib\",\n",
    "    \"black\",\n",
    "    \"thefuck\",\n",
    "    \"scrapy\",\n",
    "    \"pandas\",\n",
    "    \"luigi\",\n",
    "    \"ansible\",\n",
    "]\n",
    "\n",
    "# Print header\n",
    "print(f\"{'Project':<15} {'Passed':>6} {'Failed':>6} {'Total':>6} {'Success Rate':>13}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Print each project in order\n",
    "for project in ordered_projects:\n",
    "    stats = data[\"success_projects\"][project]\n",
    "    passed = stats[\"passed\"]\n",
    "    failed = stats[\"failed\"]\n",
    "    total = stats[\"total\"]\n",
    "    rate = stats[\"success_rate\"]\n",
    "    print(rate)\n",
    "\n",
    "# Print overall success rate\n",
    "print(\"\\nOverall Success Rate:\", f\"{data['success_rate'] * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
